---
title: "Investigating sampling bias in S-gene target results among Covid-19 test-positive cases"
author: "Epiforecasts"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include = TRUE, 
                      warning = FALSE, message = FALSE,
                      root.dir = here::here())
options(scipen = 1, digits = 2)
library(here)
library(forecast.vocs)
library(purrr)
library(dplyr)
library(scoringutils)
library(loo)
library(ggplot2)
library(knitr)
# get data and parameters without rebuilding model
run_model <- TRUE
source(here("sampling", "model-sampling.R"))
# both models are fit to raw or smooth (7-day MA) data. Select which to show for results
data_types <- c("data-raw", "data-smooth")
data_type <- data_types[1] # use fit to raw data
obs <- datasets[[data_type]]
```
### Background

When processing a positive test result for Covid-19 it is also possible to detect the S-gene target (SGT). A test for SGT can give either a failure or a positive result. The proportion of cases that are tested for SGT and result in SGT-Failure is a useful proxy for the proportion of the Omicron variant in comparison to the Delta variant. 

Only a sample of positive Covid-19 test results are also tested for SGT. The ability to test for SGT depends on type of Covid-19 test (only PCR), and laboratory resources. If these constraints are associated with factors influencing transmission, this would bias estimates of transmission made only from SGT data and confound the relationship between SGT results and all test-positive cases. 

We aim to explore bias in the availability of S-gene target results among cases testing positive for Covid-19. Here we use a branching process model to identify any difference in growth rate between cases which have an SGT result and those which do not.

### Methods

We used a two-strain branching process model to compare all test-positive cases to test-positive cases with any SGT result. We used data for all England test-positive cases. We used only the most recent three weeks of data between `r min(obs$date)` and `r max(obs$date)`. 

We estimated a daily growth rate and allowed weekly piecewise constant variation. We used a uniform prior for the initial growth rate advantage of SGT-result cases compared to no-SGT-result cases. We estimated the transmission advantage as the difference in growth rate between the two sets of cases on a daily scale. We used the `forecast.vocs` package^[2021, Sam Abbott, forecast.vocs: Forecast case and sequence notifications using variant of concern strain dynamics, DOI: 10.5281/zenodo.5559016] and fit the model using MCMC with 4000 samples.

We fit to data that contained a day-of-week reporting artefact. To test the imapct of this, we repeated the analysis using a 7-day moving average of total cases and those with SGT results. We compared results for transmission advantage and scored each model fit.

### Results

```{r load-forecasts}
# get model outputs
forecast_fits <- readRDS(here("sampling", data_type, "fit", "forecast-fits.rds"))[[variant_relationships]]
forecasts <- readRDS(here("sampling", data_type, "fit", "forecasts.rds"))[[variant_relationships]]

# Plot transmission advantage
advantage <- forecasts %>%
  filter(value_type == "model" & variable == "avg_voc_advantage") %>%
  select(variant_relationship, variable, clean_name, exponentiated:ess_bulk)

voc_scaled <- plot_voc_advantage(forecasts) +
  labs(y = "Transmission advantage among SGT-tested", x = NULL)
ggsave(here("sampling", data_type, "figures", "voc_advantage.png"), voc_scaled)
```

On average, `r round(mean(obs$share_voc, na.rm=T)*100)`% cases had an SGT result. We found a median advantage for SGT-result cases of `r exp(advantage$median)` (95% credible interval `r exp(advantage$q5)` - `r exp(advantage$q95)`), scaled against cases without an SGT result. The growth rate increased over time at a similar rate between SGT-result and no-SGT-result cases (figure \ref{fig:plot-growth}).

We compared fitting to raw data against fitting to smoothed daily data (see Appendix). We found no substantial difference in transmission advantage when using smoothed data, with better predictive performance from the model using raw unsmoothed data.

```{r plot-growth, fig.cap="Growth rate for all cases (Combined), those with an S-gene target result (SGT-result) and those without"}
growth_scaled <- plot_growth(forecasts) +
  labs(y = "Growth rate", x = NULL)
ggsave(here("sampling", data_type, "figures", "growth_rate.png"), growth_scaled)
growth_scaled
```

```{r plot-cases, fig.cap="Estimates of all cases (Combined), those with an S-gene target result (SGT-result) and those without"}
cases_scaled <- plot_cases(forecasts, obs) +
  labs(x = NULL)
ggsave(here("sampling", data_type, "figures", "cases.png"), cases_scaled)
cases_scaled
```

\newpage

### Discussion

We adapted a two-strain branching process model to explore sampling bias in cases with and without an S-gene target result. We assumed that a sampling bias in cases tested for SGT would be associated with transmissibility. This meant we could detect any bias as a transmission advantage for cases with an SGT result compared to cases without an SGT result. 
For example, labs with capacity for S-gene target detection may be used preferentially to test clusters of test-positive contacts of a known Omicron variant case. This could bias estimates of transmission made only from SGT data and confound the relationship between SGT results and all test-positive cases. This in turn could create a bias in comparisons of Omicron compared to Delta.

However, we found a near-identical estimated transmission advantage with very similar trends in increasing growth rate over time between cases that have been tested for S-gene target and those that have not. Therefore, proportions of SGTF compared to all SGT-result cases are likely to be representative of the wider case population.

This analysis has limitations. Our estimates may be inaccurate where we used a fixed relationship over the three weeks to describe whether cases were given a SGT-result or not. This relationship could change over time depending on sampling strategies: for example, an increase in testing in clusters around Omicron cases, or differential testing capacity by laboratories that can test for the S-gene target. We could further explore this using a model that allows the relationship between the two case groups to vary over time depending on data.

We have not considered sampling biases not associated with transmissibility, or factors beyond the presence or absence of an SGT test. While SGT-failure is used as a proxy for Omicron strain BA.1, a modification of Omicron can also result in SGT-positivity (BA.2). If BA.2 accounts for a significant proportion of Omicron cases, this reduces the overall usefulness of SGTF data for comparing Omicron to Delta as the dominant SGT-positive strain.

To conclude, we find no evidence of a sampling bias between SGT-result cases compared to non-SGT result cases, suggesting that proportions of SGTF compared to all SGT-result cases are likely to be representative of the wider case population.

\newpage

## Appendix

We compared models using both raw data with a day-of-week effect, and smoothed data using a 7-day centred moving average on total cases and SGT-result cases.

```{r plot-raw-cases}
smooth_long <- daily_sgt_detrend %>%
  select(date, all_cases = cases, sgt_result = seq_voc) %>%
  tidyr::pivot_longer(cols = -date, names_to = "case_type") %>%
  mutate(smooth_type = "smoothed")

raw_long <- daily_sgt %>%
  filter(date %in% obs$date) %>%
  select(date, all_cases = cases, sgt_result = seq_voc) %>%
  tidyr::pivot_longer(cols = -date, names_to = "case_type") %>%
  mutate(smooth_type = "raw")

bind_rows(smooth_long, raw_long) %>%
  ggplot(aes(x = date, colour = case_type, shape = smooth_type)) +
  geom_point(aes(y = value, colour = case_type, alpha = smooth_type)) +
  geom_line(aes(y = value, alpha = smooth_type)) +
  labs(x = NULL, y = NULL,
       subtitle = "Case data") +
  theme_bw() +
  theme(legend.position = "bottom")

```

:

```{r compare-data-smooth}
# get model outputs for alternative data type
data_alt <- data_types[!grepl(data_type, data_types)]
forecast_fits_alt <- readRDS(
  here("sampling", data_alt, "fit", "forecast-fits.rds")
)[[variant_relationships]]
forecasts_alt <- readRDS(
  here("sampling", data_alt, "fit", "forecasts.rds")
)[[variant_relationships]]

# Compare transmission advantage
advantage_all <- bind_rows(forecasts %>%
                             mutate(data_type = gsub("data-", "", data_type)), 
                           forecasts_alt %>%
                             mutate(
                               data_type = gsub("data-", "", data_alt))
                              ) %>%
  filter(value_type == "model" & variable == "avg_voc_advantage") %>%
  select(data_type, median, q5, q95) %>%
  mutate(across(median:q95, exp))

kable(
  advantage_all,
  caption = "Modelled transmission advantage by data pre-processing"
)
```

```{r compare-fit}
# # Compare model fit on LOO
#...
# # Error: Not all models have the same number of data points.

# Compare model scores
both_forecasts <- list(forecasts, forecasts_alt)
scores <- map2_dfr(.x = both_forecasts, .y = gsub("data-", "", data_types),
                   ~ summary(.x, type = "cases") %>%
                    fv_score_forecast(., obs, summarise_by = "strains") %>%
                    mutate(data_type = .y))
kable(scores %>% select(data_type, interval_score:bias),
      caption = "Model scores by data pre-processing")
```


